{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34e08b3d",
   "metadata": {},
   "source": [
    "# B2C Sales - Data Wrangling and Exploratory Analisis\n",
    "\n",
    "This project showcases the first step in working with a real-world sales dataset from the B2C retail channel in Argentina.\n",
    "\n",
    "## 📌 Objective\n",
    "To clean, transform, and explore sales data using Python, with the goal of building a solid analytical base for further modeling.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97449041",
   "metadata": {},
   "source": [
    "## 1. Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ceac55",
   "metadata": {},
   "source": [
    "The dataset that we will be working consists of three different tables:\n",
    "\n",
    "    AR_PDV.csv | pointsOfSale: Metadata of points of sale (e.g., store type, region, chain)\n",
    "    AR_PRD.csv | products: Metadata of products (e.g., category, brand, presentation)\n",
    "    AR_VTA.csv | sales: Weekly sales records with volume and revenue metrics, linked by store and product\n",
    "\n",
    "The dataset was provided via a number of .zip files uploaded weekly. Our first job is to read and combine all of the .zip files to get three dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5397cd",
   "metadata": {},
   "source": [
    "### 1.1. Loading the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ca90c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for data wrangling and analysis\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8c5423e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zip files: \n",
      "['VENTAS_ANON_20240309.zip', 'VENTAS_ANON_20240316.zip', 'VENTAS_ANON_20240323.zip', 'VENTAS_ANON_20240330.zip', 'VENTAS_ANON_20240406.zip', 'VENTAS_ANON_20240413.zip', 'VENTAS_ANON_20240420.zip', 'VENTAS_ANON_20240427.zip', 'VENTAS_ANON_20240504.zip', 'VENTAS_ANON_20240511.zip', 'VENTAS_ANON_20240518.zip', 'VENTAS_ANON_20240525.zip', 'VENTAS_ANON_20240601.zip', 'VENTAS_ANON_20240608.zip', 'VENTAS_ANON_20240615.zip']\n"
     ]
    }
   ],
   "source": [
    "# Path one step above, into data folder\n",
    "path_files = r'../data/B2C Sales - Data Wrangling and EDA'\n",
    "\n",
    "zip_files = [f for f in os.listdir(path_files) if f.endswith('.zip')]\n",
    "# Order the list of zip files by their name\n",
    "zip_files.sort(reverse=False)\n",
    "\n",
    "print(\"Zip files: \")\n",
    "print(zip_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "573512fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_csv_from_zips(prefix, path_files, zip_files, verbose=True):\n",
    "    \"\"\"\n",
    "    Extract CSV files starting with `prefix` from a list of ZIP files.\n",
    "\n",
    "    Returns a single DataFrame with all files combined.\n",
    "    \"\"\"\n",
    "    dataframes = []\n",
    "\n",
    "    for zip_file in zip_files:\n",
    "        zip_path = os.path.join(path_files, zip_file)\n",
    "        with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "            for filename in z.namelist():\n",
    "                if filename.startswith(prefix) and filename.endswith('.csv'):\n",
    "#                    if verbose:\n",
    "#                        print(f\"Processing {filename} from {zip_path}\")\n",
    "                    with z.open(filename) as f:\n",
    "                        df = pd.read_csv(f, delimiter=';')\n",
    "                        df['file_name'] = filename \n",
    "                        dataframes.append(df)\n",
    "\n",
    "    if not dataframes:\n",
    "        print(f\"No csv files found starting with '{prefix}'.\")\n",
    "        return pd.DataFrame()\n",
    "    else:\n",
    "        df_final = pd.concat(dataframes, ignore_index=True)\n",
    "        if verbose:\n",
    "            print(f\"{prefix} successfully processed. Total rows: {len(df_final)}\")\n",
    "        return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "123f12ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AR_VTA successfully processed. Total rows: 3615562\n",
      "AR_PRD successfully processed. Total rows: 32420\n",
      "AR_PDV successfully processed. Total rows: 27297\n"
     ]
    }
   ],
   "source": [
    "sales = extract_csv_from_zips(\"AR_VTA\", path_files, zip_files)\n",
    "products = extract_csv_from_zips(\"AR_PRD\", path_files, zip_files)\n",
    "pointsOfSale = extract_csv_from_zips(\"AR_PDV\", path_files, zip_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b67413f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Semana_Inicio_Semana",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Codigo_Unico_PDV",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "PDV_Comparables",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Codigo_Barras_SKU",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Categoria",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Cantidad_Contenido_SKU",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Cantidad_de_Venta",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Precio_por_Unidade",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "file_name",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "3e6a8a90-e4ab-4f99-afb2-adbf99be39b8",
       "rows": [
        [
         "0",
         "20230619",
         "ID0001",
         "0",
         "ID0001",
         "ID0001",
         "160.0",
         "2",
         "1118,40",
         "AR_VTA_20240309.csv"
        ],
        [
         "1",
         "20230612",
         "ID0002",
         "1",
         "ID0002",
         "ID0001",
         "320.0",
         "2",
         "3040,00",
         "AR_VTA_20240309.csv"
        ],
        [
         "2",
         "20230522",
         "ID0003",
         "1",
         "ID0003",
         "ID0002",
         "225.0",
         "4",
         "1760,00",
         "AR_VTA_20240309.csv"
        ],
        [
         "3",
         "20230612",
         "ID0004",
         "0",
         "ID0004",
         "ID0003",
         "160.0",
         "2",
         "1208,18",
         "AR_VTA_20240309.csv"
        ],
        [
         "4",
         "20230605",
         "ID0005",
         "0",
         "ID0005",
         "ID0002",
         "225.0",
         "1",
         "239,25",
         "AR_VTA_20240309.csv"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Semana_Inicio_Semana</th>\n",
       "      <th>Codigo_Unico_PDV</th>\n",
       "      <th>PDV_Comparables</th>\n",
       "      <th>Codigo_Barras_SKU</th>\n",
       "      <th>Categoria</th>\n",
       "      <th>Cantidad_Contenido_SKU</th>\n",
       "      <th>Cantidad_de_Venta</th>\n",
       "      <th>Precio_por_Unidade</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230619</td>\n",
       "      <td>ID0001</td>\n",
       "      <td>0</td>\n",
       "      <td>ID0001</td>\n",
       "      <td>ID0001</td>\n",
       "      <td>160.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1118,40</td>\n",
       "      <td>AR_VTA_20240309.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20230612</td>\n",
       "      <td>ID0002</td>\n",
       "      <td>1</td>\n",
       "      <td>ID0002</td>\n",
       "      <td>ID0001</td>\n",
       "      <td>320.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3040,00</td>\n",
       "      <td>AR_VTA_20240309.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20230522</td>\n",
       "      <td>ID0003</td>\n",
       "      <td>1</td>\n",
       "      <td>ID0003</td>\n",
       "      <td>ID0002</td>\n",
       "      <td>225.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1760,00</td>\n",
       "      <td>AR_VTA_20240309.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20230612</td>\n",
       "      <td>ID0004</td>\n",
       "      <td>0</td>\n",
       "      <td>ID0004</td>\n",
       "      <td>ID0003</td>\n",
       "      <td>160.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1208,18</td>\n",
       "      <td>AR_VTA_20240309.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20230605</td>\n",
       "      <td>ID0005</td>\n",
       "      <td>0</td>\n",
       "      <td>ID0005</td>\n",
       "      <td>ID0002</td>\n",
       "      <td>225.0</td>\n",
       "      <td>1</td>\n",
       "      <td>239,25</td>\n",
       "      <td>AR_VTA_20240309.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Semana_Inicio_Semana Codigo_Unico_PDV  PDV_Comparables Codigo_Barras_SKU  \\\n",
       "0              20230619           ID0001                0            ID0001   \n",
       "1              20230612           ID0002                1            ID0002   \n",
       "2              20230522           ID0003                1            ID0003   \n",
       "3              20230612           ID0004                0            ID0004   \n",
       "4              20230605           ID0005                0            ID0005   \n",
       "\n",
       "  Categoria  Cantidad_Contenido_SKU  Cantidad_de_Venta Precio_por_Unidade  \\\n",
       "0    ID0001                   160.0                  2            1118,40   \n",
       "1    ID0001                   320.0                  2            3040,00   \n",
       "2    ID0002                   225.0                  4            1760,00   \n",
       "3    ID0003                   160.0                  2            1208,18   \n",
       "4    ID0002                   225.0                  1             239,25   \n",
       "\n",
       "             file_name  \n",
       "0  AR_VTA_20240309.csv  \n",
       "1  AR_VTA_20240309.csv  \n",
       "2  AR_VTA_20240309.csv  \n",
       "3  AR_VTA_20240309.csv  \n",
       "4  AR_VTA_20240309.csv  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6281470d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "PRD_CODIGO",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "CATEGORIA_SKU",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "PROVEEDOR_SKU",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "MARCA_SKU",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "NOMBRE_SKU",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "CODIGO_BARRAS_SKU",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "PROD_CANT_CONTENIDO",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "file_name",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "37b08bd8-ef53-4b95-a245-fe1128e43a14",
       "rows": [
        [
         "0",
         "ID0001",
         "ID0001",
         "ID0001",
         "ID0001",
         "ID0001",
         "ID0001",
         "300.0",
         "AR_PRD_20240309.csv"
        ],
        [
         "1",
         "ID0002",
         "ID0002",
         "ID0002",
         "ID0002",
         "ID0002",
         "ID0002",
         "500.0",
         "AR_PRD_20240309.csv"
        ],
        [
         "2",
         "ID0003",
         "ID0002",
         "ID0002",
         "ID0002",
         "ID0003",
         "ID0003",
         null,
         "AR_PRD_20240309.csv"
        ],
        [
         "3",
         "ID0004",
         "ID0003",
         "ID0002",
         "ID0002",
         "ID0004",
         "ID0004",
         "380.0",
         "AR_PRD_20240309.csv"
        ],
        [
         "4",
         "ID0005",
         "ID0004",
         "ID0003",
         "ID0003",
         "ID0005",
         "ID0005",
         "375.0",
         "AR_PRD_20240309.csv"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRD_CODIGO</th>\n",
       "      <th>CATEGORIA_SKU</th>\n",
       "      <th>PROVEEDOR_SKU</th>\n",
       "      <th>MARCA_SKU</th>\n",
       "      <th>NOMBRE_SKU</th>\n",
       "      <th>CODIGO_BARRAS_SKU</th>\n",
       "      <th>PROD_CANT_CONTENIDO</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID0001</td>\n",
       "      <td>ID0001</td>\n",
       "      <td>ID0001</td>\n",
       "      <td>ID0001</td>\n",
       "      <td>ID0001</td>\n",
       "      <td>ID0001</td>\n",
       "      <td>300.0</td>\n",
       "      <td>AR_PRD_20240309.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID0002</td>\n",
       "      <td>ID0002</td>\n",
       "      <td>ID0002</td>\n",
       "      <td>ID0002</td>\n",
       "      <td>ID0002</td>\n",
       "      <td>ID0002</td>\n",
       "      <td>500.0</td>\n",
       "      <td>AR_PRD_20240309.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID0003</td>\n",
       "      <td>ID0002</td>\n",
       "      <td>ID0002</td>\n",
       "      <td>ID0002</td>\n",
       "      <td>ID0003</td>\n",
       "      <td>ID0003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AR_PRD_20240309.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID0004</td>\n",
       "      <td>ID0003</td>\n",
       "      <td>ID0002</td>\n",
       "      <td>ID0002</td>\n",
       "      <td>ID0004</td>\n",
       "      <td>ID0004</td>\n",
       "      <td>380.0</td>\n",
       "      <td>AR_PRD_20240309.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID0005</td>\n",
       "      <td>ID0004</td>\n",
       "      <td>ID0003</td>\n",
       "      <td>ID0003</td>\n",
       "      <td>ID0005</td>\n",
       "      <td>ID0005</td>\n",
       "      <td>375.0</td>\n",
       "      <td>AR_PRD_20240309.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PRD_CODIGO CATEGORIA_SKU PROVEEDOR_SKU MARCA_SKU NOMBRE_SKU  \\\n",
       "0     ID0001        ID0001        ID0001    ID0001     ID0001   \n",
       "1     ID0002        ID0002        ID0002    ID0002     ID0002   \n",
       "2     ID0003        ID0002        ID0002    ID0002     ID0003   \n",
       "3     ID0004        ID0003        ID0002    ID0002     ID0004   \n",
       "4     ID0005        ID0004        ID0003    ID0003     ID0005   \n",
       "\n",
       "  CODIGO_BARRAS_SKU  PROD_CANT_CONTENIDO            file_name  \n",
       "0            ID0001                300.0  AR_PRD_20240309.csv  \n",
       "1            ID0002                500.0  AR_PRD_20240309.csv  \n",
       "2            ID0003                  NaN  AR_PRD_20240309.csv  \n",
       "3            ID0004                380.0  AR_PRD_20240309.csv  \n",
       "4            ID0005                375.0  AR_PRD_20240309.csv  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "666a3c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "CODIGO_PDV",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "CODIGO_UNICO_PDV",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "NOMBRE_PDV",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "DIRECCION_PDV",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "COMPARABLES_HOY",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "AREA_P",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ZONA_MODELO_B",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "CLUSTER_PDV",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ESTADO_PDV",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "LOCALIDAD_PDV",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ZONA_P",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "file_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "RUC",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "9eb30f06-e59f-4f2e-ab2d-6853bd1002ed",
       "rows": [
        [
         "0",
         "ID0001",
         "ID0001",
         "ID0001",
         "ID0001",
         "1",
         "Interior",
         "NEA",
         "Autoservicio Mediano",
         "CHACO",
         "RESISTENCIA",
         "CHACO RESISTENCIA",
         "AR_PDV_20240309.csv",
         null
        ],
        [
         "1",
         "ID0002",
         "ID0002",
         "ID0002",
         "ID0002",
         "0",
         "Interior",
         "NOA",
         null,
         "TUCUMAN",
         "LULES",
         "TUCUMAN INTERIOR",
         "AR_PDV_20240309.csv",
         null
        ],
        [
         "2",
         "ID0003",
         "ID0003",
         "ID0003",
         "ID0003",
         "1",
         "Interior",
         "LITORAL",
         "Autoservicio Mediano",
         "ENTRE RIOS",
         "PARANA",
         "ENTRE RIOS PARANA",
         "AR_PDV_20240309.csv",
         null
        ],
        [
         "3",
         "ID0004",
         "ID0004",
         "ID0004",
         "ID0004",
         "0",
         "Metropolitana",
         "CAPITAL FEDERAL",
         "Autoservicio Chico",
         "BUENOS AIRES",
         "CAPITAL FEDERAL",
         "C.A.B.A",
         "AR_PDV_20240309.csv",
         null
        ],
        [
         "4",
         "ID0005",
         "ID0005",
         "ID0005",
         "ID0005",
         "0",
         "Interior",
         "CORDOBA",
         null,
         "CORDOBA",
         "Cordoba",
         "CORDOBA CAPITAL",
         "AR_PDV_20240309.csv",
         null
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODIGO_PDV</th>\n",
       "      <th>CODIGO_UNICO_PDV</th>\n",
       "      <th>NOMBRE_PDV</th>\n",
       "      <th>DIRECCION_PDV</th>\n",
       "      <th>COMPARABLES_HOY</th>\n",
       "      <th>AREA_P</th>\n",
       "      <th>ZONA_MODELO_B</th>\n",
       "      <th>CLUSTER_PDV</th>\n",
       "      <th>ESTADO_PDV</th>\n",
       "      <th>LOCALIDAD_PDV</th>\n",
       "      <th>ZONA_P</th>\n",
       "      <th>file_name</th>\n",
       "      <th>RUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID0001</td>\n",
       "      <td>ID0001</td>\n",
       "      <td>ID0001</td>\n",
       "      <td>ID0001</td>\n",
       "      <td>1</td>\n",
       "      <td>Interior</td>\n",
       "      <td>NEA</td>\n",
       "      <td>Autoservicio Mediano</td>\n",
       "      <td>CHACO</td>\n",
       "      <td>RESISTENCIA</td>\n",
       "      <td>CHACO RESISTENCIA</td>\n",
       "      <td>AR_PDV_20240309.csv</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID0002</td>\n",
       "      <td>ID0002</td>\n",
       "      <td>ID0002</td>\n",
       "      <td>ID0002</td>\n",
       "      <td>0</td>\n",
       "      <td>Interior</td>\n",
       "      <td>NOA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TUCUMAN</td>\n",
       "      <td>LULES</td>\n",
       "      <td>TUCUMAN INTERIOR</td>\n",
       "      <td>AR_PDV_20240309.csv</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID0003</td>\n",
       "      <td>ID0003</td>\n",
       "      <td>ID0003</td>\n",
       "      <td>ID0003</td>\n",
       "      <td>1</td>\n",
       "      <td>Interior</td>\n",
       "      <td>LITORAL</td>\n",
       "      <td>Autoservicio Mediano</td>\n",
       "      <td>ENTRE RIOS</td>\n",
       "      <td>PARANA</td>\n",
       "      <td>ENTRE RIOS PARANA</td>\n",
       "      <td>AR_PDV_20240309.csv</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID0004</td>\n",
       "      <td>ID0004</td>\n",
       "      <td>ID0004</td>\n",
       "      <td>ID0004</td>\n",
       "      <td>0</td>\n",
       "      <td>Metropolitana</td>\n",
       "      <td>CAPITAL FEDERAL</td>\n",
       "      <td>Autoservicio Chico</td>\n",
       "      <td>BUENOS AIRES</td>\n",
       "      <td>CAPITAL FEDERAL</td>\n",
       "      <td>C.A.B.A</td>\n",
       "      <td>AR_PDV_20240309.csv</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID0005</td>\n",
       "      <td>ID0005</td>\n",
       "      <td>ID0005</td>\n",
       "      <td>ID0005</td>\n",
       "      <td>0</td>\n",
       "      <td>Interior</td>\n",
       "      <td>CORDOBA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CORDOBA</td>\n",
       "      <td>Cordoba</td>\n",
       "      <td>CORDOBA CAPITAL</td>\n",
       "      <td>AR_PDV_20240309.csv</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CODIGO_PDV CODIGO_UNICO_PDV NOMBRE_PDV DIRECCION_PDV  COMPARABLES_HOY  \\\n",
       "0     ID0001           ID0001     ID0001        ID0001                1   \n",
       "1     ID0002           ID0002     ID0002        ID0002                0   \n",
       "2     ID0003           ID0003     ID0003        ID0003                1   \n",
       "3     ID0004           ID0004     ID0004        ID0004                0   \n",
       "4     ID0005           ID0005     ID0005        ID0005                0   \n",
       "\n",
       "          AREA_P    ZONA_MODELO_B           CLUSTER_PDV    ESTADO_PDV  \\\n",
       "0       Interior              NEA  Autoservicio Mediano         CHACO   \n",
       "1       Interior              NOA                   NaN       TUCUMAN   \n",
       "2       Interior          LITORAL  Autoservicio Mediano    ENTRE RIOS   \n",
       "3  Metropolitana  CAPITAL FEDERAL    Autoservicio Chico  BUENOS AIRES   \n",
       "4       Interior          CORDOBA                   NaN       CORDOBA   \n",
       "\n",
       "     LOCALIDAD_PDV             ZONA_P            file_name  RUC  \n",
       "0      RESISTENCIA  CHACO RESISTENCIA  AR_PDV_20240309.csv  NaN  \n",
       "1            LULES   TUCUMAN INTERIOR  AR_PDV_20240309.csv  NaN  \n",
       "2           PARANA  ENTRE RIOS PARANA  AR_PDV_20240309.csv  NaN  \n",
       "3  CAPITAL FEDERAL            C.A.B.A  AR_PDV_20240309.csv  NaN  \n",
       "4          Cordoba    CORDOBA CAPITAL  AR_PDV_20240309.csv  NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pointsOfSale.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bedf66b",
   "metadata": {},
   "source": [
    "We now have the three datasets loaded in memory. With this, we move on to the data cleaning.\n",
    "\n",
    "As a good practice, we leave an internal copy of the raw data as a back-up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a657f399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save raw data copies for backup\n",
    "sales_raw = sales.copy()\n",
    "products_raw = products.copy()\n",
    "pointsOfSale_raw = pointsOfSale.copy() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16771883",
   "metadata": {},
   "source": [
    "### 1.2 Data Cleaning\n",
    "\n",
    "Now we move on to the data cleaning, including:\n",
    "- Drop duplicates\n",
    "- Check and convert data types\n",
    "- Normalize key fields\n",
    "- Assess missing values\n",
    "- Prepare for joining datasets\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2388a4",
   "metadata": {},
   "source": [
    "#### 🧾 Metadata Overview\n",
    "Below is a quick reference of the columns contained in each of the three dataframes:\n",
    "\n",
    "##### 📍 pointsOfSale (AR_PDV.csv)\n",
    "Contains metadata about each point of sale (store), such as its unique identifier, location, and segmentation information.\n",
    "\n",
    "- *CODIGO_PDV: Internal store code (anonymized)*\n",
    "- *CODIGO_UNICO_PDV: Unique point-of-sale identifier (anonymized)*\n",
    "- *NOMBRE_PDV: Store name (anonymized)*\n",
    "- *DIRECCION_PDV: Store address (anonymized)*\n",
    "- *COMPARABLES_HOY: Store comparability flag*\n",
    "- *AREA_P: Geographical area or region*\n",
    "- *RUC: Tax ID or business ID (optional / not always present)*\n",
    "- *ZONA_MODELO_B: Internal model segmentation*\n",
    "- *CLUSTER_PDV: Store cluster (used for grouping stores by behavior or profile)*\n",
    "- *ESTADO_PDV: Store status (e.g., active, inactive)*\n",
    "- *LOCALIDAD_PDV: City or locality*\n",
    "- *ZONA_P: Internal geographic segmentation*\n",
    "- *file_name: Source file from which the row was extracted*\n",
    "\n",
    "##### 📦 products (AR_PRD.csv)\n",
    "Contains product-level metadata, useful for grouping and analysis by brand, category, or SKU.\n",
    "\n",
    "- *PRD_CODIGO: Internal product code (anonymized)*\n",
    "- *CATEGORIA_SKU: Product category (anonymized)*\n",
    "- *PROVEEDOR_SKU: Product supplier or manufacturer (anonymized)*\n",
    "- *MARCA_SKU: Brand name (anonymized)*\n",
    "- *NOMBRE_SKU: Product description or label (anonymized)*\n",
    "- *CODIGO_BARRAS_SKU: Barcode identifier (anonymized)*\n",
    "- *PROD_CANT_CONTENIDO: Net content or pack size (e.g., grams, liters)*\n",
    "- *file_name: Source file from which the row was extracted*\n",
    "\n",
    "##### 🛒 sales (AR_VTA.csv)\n",
    "Contains transactional sales data, with weekly granularity and links to stores and products.\n",
    "\n",
    "- *Semana_Inicio_Semana: Starting date of the week (used for time series analysis)*\n",
    "- *Codigo_Unico_PDV: Unique store identifier (anonymized)*\n",
    "- *PDV_Comparables: Flag indicating whether the store is part of comparable set*\n",
    "- *Codigo_Barras_SKU: Product identifier (anonymized)*\n",
    "- *Categoria: Product category (anonymized)*\n",
    "- *Cantidad_Contenido_SKU: Net content of the SKU*\n",
    "- *Cantidad_de_Venta: Units sold*\n",
    "- *Precio_por_Unidade: Price per unit sold*\n",
    "- *file_name: Source file from which the row was extracted*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639f8bd6",
   "metadata": {},
   "source": [
    "#### 1.2.1 Drop duplicates\n",
    "From the metadata, we can identify the key fields from each table:\n",
    "- pointsOfSale: Either CODIGO_PDV or CODIGO_UNICO_PDV → We choose CODIGO_UNICO_PDV to join to the sales dataframe\n",
    "- products: Either PRD_CODIGO or CODIGO_BARRAS_SKU → We choose CODIGO_BARRAS_SKU to join to the sales dataframe\n",
    "- sales: Semana_Inicio_Semana + Codigo_Unico_PDV + Codigo_Barras_SKU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "101021b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify key fields for each table\n",
    "pointsOfSale_key = ['CODIGO_UNICO_PDV']\n",
    "products_key = ['CODIGO_BARRAS_SKU']\n",
    "sales_key = ['Semana_Inicio_Semana', 'Codigo_Unico_PDV', 'Codigo_Barras_SKU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b24589d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates in pointOfSale: 25463 out of 27297 ( 93.3 % )\n",
      "Duplicates in products: 30264 out of 32420 ( 93.3 % )\n",
      "Duplicates in sales: 860447 out of 3615562 ( 23.8 % )\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in pointsOfSale\n",
    "print(\"Duplicates in pointOfSale:\",\n",
    "      pointsOfSale.duplicated(subset=pointsOfSale_key).sum(),\n",
    "      \"out of\", len(pointsOfSale),\n",
    "      \"(\", round(pointsOfSale.duplicated(subset=pointsOfSale_key).sum() / len(pointsOfSale) * 100, 1), \"% )\")\n",
    "print(\"Duplicates in products:\",\n",
    "      products.duplicated(subset=products_key).sum(),\n",
    "      \"out of\", len(products),\n",
    "      \"(\", round(products.duplicated(subset=products_key).sum() / len(products) * 100, 1), \"% )\")\n",
    "print(\"Duplicates in sales:\",\n",
    "      sales.duplicated(subset=sales_key).sum(),\n",
    "      \"out of\", len(sales),\n",
    "      \"(\", round(sales.duplicated(subset=sales_key).sum() / len(sales) * 100, 1), \"% )\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e6eaca",
   "metadata": {},
   "source": [
    "In both pointofSale and products, the duplicates are expected, because we merged metadata tables.\n",
    "However in sales, duplicates are not expected, which means that in each individual file there was data for more than one week.\n",
    "\n",
    "\n",
    "Here we make an important assumption that should always be validated: We will eliminate the duplicates by always leaving the last occurance, by file name (which is correspondent to when the file was created). However, this is only correct in context for this data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe54a22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminate duplicates by keeping the last occurrence\n",
    "pointsOfSale = pointsOfSale.drop_duplicates(subset=pointsOfSale_key, keep='last')\n",
    "products = products.drop_duplicates(subset=products_key, keep='last')\n",
    "sales = sales.drop_duplicates(subset=sales_key, keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23fbd724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates in pointOfSale: 0 out of 1834 ( 0.0 % )\n",
      "Duplicates in products: 0 out of 2156 ( 0.0 % )\n",
      "Duplicates in sales: 0 out of 2755115 ( 0.0 % )\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in pointsOfSale\n",
    "print(\"Duplicates in pointOfSale:\",\n",
    "      pointsOfSale.duplicated(subset=pointsOfSale_key).sum(),\n",
    "      \"out of\", len(pointsOfSale),\n",
    "      \"(\", round(pointsOfSale.duplicated(subset=pointsOfSale_key).sum() / len(pointsOfSale) * 100, 1), \"% )\")\n",
    "print(\"Duplicates in products:\",\n",
    "      products.duplicated(subset=products_key).sum(),\n",
    "      \"out of\", len(products),\n",
    "      \"(\", round(products.duplicated(subset=products_key).sum() / len(products) * 100, 1), \"% )\")\n",
    "print(\"Duplicates in sales:\",\n",
    "      sales.duplicated(subset=sales_key).sum(),\n",
    "      \"out of\", len(sales),\n",
    "      \"(\", round(sales.duplicated(subset=sales_key).sum() / len(sales) * 100, 1), \"% )\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8501b3",
   "metadata": {},
   "source": [
    "Now rows have no duplicates, however we still have either duplicated fields, or multiple ID fields in our tables. We will also remove the filename column from the tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78a6d968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminate duplicated fields\n",
    "cols_to_drop = {\n",
    "    \"pointsOfSale\": [\n",
    "        'CODIGO_PDV',\n",
    "        'file_name'],\n",
    "    \"products\": [\n",
    "        'PRD_CODIGO',\n",
    "        'file_name'],\n",
    "    \"sales\": [\n",
    "              'PDV_Comparables',\n",
    "              'Categoria',\n",
    "              'Cantidad_Contenido_SKU',\n",
    "              'file_name']\n",
    "}\n",
    "for df_name, cols in cols_to_drop.items():\n",
    "    if df_name == \"pointsOfSale\":\n",
    "        pointsOfSale.drop(columns=cols, inplace=True)\n",
    "    elif df_name == \"products\":\n",
    "        products.drop(columns=cols, inplace=True)\n",
    "    elif df_name == \"sales\":\n",
    "        sales.drop(columns=cols, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d03bc44",
   "metadata": {},
   "source": [
    "#### 1.2.2 Check and convert Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac069d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types in pointsOfSale:\n",
      "CODIGO_UNICO_PDV    object\n",
      "NOMBRE_PDV          object\n",
      "DIRECCION_PDV       object\n",
      "COMPARABLES_HOY      int64\n",
      "AREA_P              object\n",
      "ZONA_MODELO_B       object\n",
      "CLUSTER_PDV         object\n",
      "ESTADO_PDV          object\n",
      "LOCALIDAD_PDV       object\n",
      "ZONA_P              object\n",
      "RUC                 object\n",
      "dtype: object\n",
      "\n",
      "Data types in products:\n",
      "CATEGORIA_SKU           object\n",
      "PROVEEDOR_SKU           object\n",
      "MARCA_SKU               object\n",
      "NOMBRE_SKU              object\n",
      "CODIGO_BARRAS_SKU       object\n",
      "PROD_CANT_CONTENIDO    float64\n",
      "dtype: object\n",
      "\n",
      "Data types in sales:\n",
      "Semana_Inicio_Semana     int64\n",
      "Codigo_Unico_PDV        object\n",
      "Codigo_Barras_SKU       object\n",
      "Cantidad_de_Venta        int64\n",
      "Precio_por_Unidade      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check data types\n",
    "print(\"Data types in pointsOfSale:\")\n",
    "print(pointsOfSale.dtypes) \n",
    "print(\"\\nData types in products:\")\n",
    "print(products.dtypes)\n",
    "print(\"\\nData types in sales:\")\n",
    "print(sales.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b942574",
   "metadata": {},
   "source": [
    "Most of the data types are already appropriate for analysis, but we will convert some columns to string and float as needed.\n",
    "\n",
    "The column COMPARABLES_HOY will be converted to boolean.\n",
    "\n",
    "Lastly to note, the column Precio_por_Unidade in sales is currently a string, but it should be a float. We will convert it to float after removing the currency symbol and commas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7f67cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns to string in all dataframes\n",
    "cols_to_str = {\n",
    "    \"pointsOfSale\": ['CODIGO_UNICO_PDV', 'NOMBRE_PDV', 'DIRECCION_PDV',\n",
    "       'AREA_P', 'ZONA_MODELO_B', 'CLUSTER_PDV', 'ESTADO_PDV', 'LOCALIDAD_PDV',\n",
    "       'ZONA_P', 'RUC'],\n",
    "    \"products\": ['CATEGORIA_SKU', 'PROVEEDOR_SKU', 'MARCA_SKU', 'NOMBRE_SKU',\n",
    "       'CODIGO_BARRAS_SKU'],\n",
    "    \"sales\": ['Codigo_Unico_PDV', 'Codigo_Barras_SKU']\n",
    "}\n",
    "\n",
    "for col in cols_to_str[\"pointsOfSale\"]:\n",
    "    pointsOfSale[col] = pointsOfSale[col].astype(str)\n",
    "\n",
    "for col in cols_to_str[\"products\"]:\n",
    "    products[col] = products[col].astype(str)\n",
    "\n",
    "for col in cols_to_str[\"sales\"]:\n",
    "    sales[col] = sales[col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2912edc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert COMPARABLES_HOY to boolean\n",
    "pointsOfSale['COMPARABLES_HOY'] = pointsOfSale['COMPARABLES_HOY'].replace({'SI': True, 'NO': False})\n",
    "pointsOfSale['COMPARABLES_HOY'] = pointsOfSale['COMPARABLES_HOY'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ac34358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace commas with dots in numeric columns and convert to float\n",
    "cols_to_replace = {\n",
    "    \"pointsOfSale\": [],\n",
    "    \"products\": ['PROD_CANT_CONTENIDO'],\n",
    "    \"sales\": ['Cantidad_de_Venta', 'Precio_por_Unidade']\n",
    "}\n",
    "for col in cols_to_replace[\"pointsOfSale\"]:\n",
    "    pointsOfSale[col] = pointsOfSale[col].astype(str).str.replace(',', '.').astype(float)\n",
    "for col in cols_to_replace[\"products\"]:\n",
    "    products[col] = products[col].astype(str).str.replace(',', '.').astype(float)\n",
    "for col in cols_to_replace[\"sales\"]:\n",
    "    sales[col] = sales[col].astype(str).str.replace(',', '.').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a94444bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Semana_Inicio_Semana to datetime\n",
    "sales['Semana_Inicio_Semana'] = pd.to_datetime(sales['Semana_Inicio_Semana'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ff29c205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types in pointsOfSale:\n",
      "CODIGO_UNICO_PDV    object\n",
      "NOMBRE_PDV          object\n",
      "DIRECCION_PDV       object\n",
      "COMPARABLES_HOY       bool\n",
      "AREA_P              object\n",
      "ZONA_MODELO_B       object\n",
      "CLUSTER_PDV         object\n",
      "ESTADO_PDV          object\n",
      "LOCALIDAD_PDV       object\n",
      "ZONA_P              object\n",
      "RUC                 object\n",
      "dtype: object\n",
      "\n",
      "Data types in products:\n",
      "CATEGORIA_SKU           object\n",
      "PROVEEDOR_SKU           object\n",
      "MARCA_SKU               object\n",
      "NOMBRE_SKU              object\n",
      "CODIGO_BARRAS_SKU       object\n",
      "PROD_CANT_CONTENIDO    float64\n",
      "dtype: object\n",
      "\n",
      "Data types in sales:\n",
      "Semana_Inicio_Semana    datetime64[ns]\n",
      "Codigo_Unico_PDV                object\n",
      "Codigo_Barras_SKU               object\n",
      "Cantidad_de_Venta              float64\n",
      "Precio_por_Unidade             float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check data types\n",
    "print(\"Data types in pointsOfSale:\")\n",
    "print(pointsOfSale.dtypes) \n",
    "print(\"\\nData types in products:\")\n",
    "print(products.dtypes)\n",
    "print(\"\\nData types in sales:\")\n",
    "print(sales.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ce4623",
   "metadata": {},
   "source": [
    "#### 1.2.3 Normalize key fields (coming soon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601c8f04",
   "metadata": {},
   "source": [
    "#### 1.2.4 Assess missing values (coming soon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cfc8a8",
   "metadata": {},
   "source": [
    "#### 1.2.5 Prepare for joining datasets (coming soon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531ccb2e",
   "metadata": {},
   "source": [
    "### 1.3 Preparing for joins (coming soon)\n",
    "\n",
    "After cleaning each individual dataset, we verify that the key fields are suitable for merging:\n",
    "\n",
    "- AR_VTA can be joined with AR_PDV using `Codigo_Unico_PDV`\n",
    "- AR_VTA can be joined with AR_PRD using `Codigo_Barras_SKU`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b5cfdc",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (coming soon)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
